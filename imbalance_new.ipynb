{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "labeled-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from scipy import interp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#from sklearn import cross_validate, metrics\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import sklearn.tree as tree\n",
    "datatotal=pd.read_csv(\"Perfect.csv\")\n",
    "X=datatotal.drop(['Y'],axis=1)\n",
    "#datatotal=datatotal.drop(['Orthostatis'],axis=1)\n",
    "#X[\"X26\"]=X[\"X26\"]-1\n",
    "#X[\"X27\"]=X[\"X27\"]-1\n",
    "#X[\"X28\"]=X[\"X28\"]-1\n",
    "#X=preprocessing.scale(X)\n",
    "n=X.shape[0]\n",
    "Y=datatotal[\"Y\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "removable-scheduling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>22.06</td>\n",
       "      <td>76</td>\n",
       "      <td>4.72</td>\n",
       "      <td>494</td>\n",
       "      <td>4.17</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.94</td>\n",
       "      <td>157.23</td>\n",
       "      <td>29.65</td>\n",
       "      <td>0.23</td>\n",
       "      <td>64</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>23.91</td>\n",
       "      <td>78</td>\n",
       "      <td>5.13</td>\n",
       "      <td>382</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.32</td>\n",
       "      <td>92.39</td>\n",
       "      <td>15.59</td>\n",
       "      <td>1.33</td>\n",
       "      <td>107</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>23.26</td>\n",
       "      <td>72</td>\n",
       "      <td>5.39</td>\n",
       "      <td>381</td>\n",
       "      <td>5.57</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.09</td>\n",
       "      <td>87.26</td>\n",
       "      <td>20.89</td>\n",
       "      <td>26.78</td>\n",
       "      <td>131</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>23.27</td>\n",
       "      <td>73</td>\n",
       "      <td>6.10</td>\n",
       "      <td>412</td>\n",
       "      <td>6.37</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>14.60</td>\n",
       "      <td>12.85</td>\n",
       "      <td>0.20</td>\n",
       "      <td>131</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>18.75</td>\n",
       "      <td>63</td>\n",
       "      <td>5.38</td>\n",
       "      <td>393</td>\n",
       "      <td>3.86</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.73</td>\n",
       "      <td>45.12</td>\n",
       "      <td>5.54</td>\n",
       "      <td>14.97</td>\n",
       "      <td>94</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2     X3  X4    X5   X6    X7    X8   X9   X10     X11    X12    X13  \\\n",
       "0   1  42  22.06  76  4.72  494  4.17  1.09  1.6  1.94  157.23  29.65   0.23   \n",
       "1   1  39  23.91  78  5.13  382  4.49  2.17  1.1  2.32   92.39  15.59   1.33   \n",
       "2   0  56  23.26  72  5.39  381  5.57  1.67  1.5  3.09   87.26  20.89  26.78   \n",
       "3   0  53  23.27  73  6.10  412  6.37  2.34  1.3  3.70   14.60  12.85   0.20   \n",
       "4   0  48  18.75  63  5.38  393  3.86  0.88  1.7  1.73   45.12   5.54  14.97   \n",
       "\n",
       "   X14  X15  X16  X17  X18  X19  X20  \n",
       "0   64   57    0    0    0    0    0  \n",
       "1  107   71    0    0    0    0    0  \n",
       "2  131   79    0    0    0    0    0  \n",
       "3  131   78    0    0    0    0    0  \n",
       "4   94   64    0    0    0    0    0  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "executed-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['X2']=preprocessing.scale(X['X2'])\n",
    "X['X3']=preprocessing.scale(X['X3'])\n",
    "X['X4']=preprocessing.scale(X['X4'])\n",
    "X['X5']=preprocessing.scale(X['X5'])\n",
    "X['X6']=preprocessing.scale(X['X6'])\n",
    "X['X7']=preprocessing.scale(X['X7'])\n",
    "X['X8']=preprocessing.scale(X['X8'])\n",
    "X['X9']=preprocessing.scale(X['X9'])\n",
    "X['X10']=preprocessing.scale(X['X10'])\n",
    "X['X11']=preprocessing.scale(X['X11'])\n",
    "X['X12']=preprocessing.scale(X['X12'])\n",
    "X['X13']=preprocessing.scale(X['X13'])\n",
    "X['X14']=preprocessing.scale(X['X14'])\n",
    "X['X15']=preprocessing.scale(X['X15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "human-study",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 20)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "needed-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.dropna(axis = 0)\n",
    "Y=Y.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "biblical-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.iloc[:,[0,2,5,9,11,12,13,14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "impossible-handling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "answering-gibraltar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 8)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fossil-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.datasets import fetch_openml\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "published-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, Y = SMOTE(k_neighbors=20,sampling_strategy=0.9).fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "visible-ending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 0.64 Precision 0.33783783783783783 Recall 0.8333333333333334 F1 0.4807692307692307 AUC 0.7287115662115662\n"
     ]
    }
   ],
   "source": [
    "dtc = tree.DecisionTreeClassifier() #Setup 10-fold CV\n",
    "seed=888\n",
    "kf = KFold(n_splits=10, shuffle=True,random_state=seed)\n",
    "matrix = np.matrix('0 0; 0 0') #Generating confusion matrix\n",
    "TN=0\n",
    "FP=0\n",
    "FN=0\n",
    "TP=0\n",
    "AUC=0\n",
    "for train_index, test_index in kf.split(X): #Iterating through each fold of CV\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "    X_train, Y_train = SMOTE(k_neighbors=20,sampling_strategy=0.9).fit_resample(X_train, Y_train)\n",
    "    dtc_cv = DecisionTreeClassifier(max_depth=3,random_state=0)\n",
    "    #ros = RandomOverSampler(random_state=0,sampling_strategy=1.5)\n",
    "   # X_train, Y_train = SMOTE(k_neighbors=20).fit_resample(X_train, Y_train)\n",
    "    #X_train, Y_train = ros.fit_resample(X_train, Y_train)\n",
    "    dtc_cv.fit(X_train, Y_train)\n",
    "    Y_pred = dtc_cv.predict(X_test)\n",
    "    matrix = np.add(matrix, confusion_matrix(Y_test, Y_pred)) #Build model and evaluate with testing data\n",
    "    tn, fp, fn, tp=confusion_matrix(np.squeeze(Y_test), np.squeeze(Y_pred)).ravel()\n",
    "    auc=roc_auc_score(Y_test, dtc_cv.predict_proba(X_test)[:, 1])\n",
    "    TN+=tn\n",
    "    FP+=fp\n",
    "    FN+=fn\n",
    "    TP+=tp\n",
    "    AUC+=auc\n",
    "acc=(TN+TP)/(TN+TP+FP+FN)  \n",
    "precision=TP/(TP+FP)\n",
    "recall=TP/(TP+FN)\n",
    "f1=2/(1/precision+1/recall)\n",
    "print(\"ACC\",acc,\"Precision\",precision,\"Recall\",recall,\"F1\",f1,\"AUC\",AUC/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "married-sensitivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 0.6933333333333334 Precision 0.23333333333333334 Recall 0.23333333333333334 F1 0.23333333333333334 AUC 0.6475177045177046\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "seed=666\n",
    "kf = KFold(n_splits=10, shuffle=True,random_state=seed)\n",
    "matrix = np.matrix('0 0; 0 0') #Generating confusion matrix\n",
    "TN=0\n",
    "FP=0\n",
    "FN=0\n",
    "TP=0\n",
    "AUC=0\n",
    "for train_index, test_index in kf.split(X): #Iterating through each fold of CV\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "    X_train, Y_train = SMOTE(k_neighbors=20,sampling_strategy=0.9).fit_resample(X_train, Y_train)\n",
    "    dtc_cv = svm.SVC(probability=True)\n",
    "    #ros = RandomOverSampler(random_state=0,sampling_strategy=1.5)\n",
    "   # X_train, Y_train = SMOTE(k_neighbors=20).fit_resample(X_train, Y_train)\n",
    "    #X_train, Y_train = ros.fit_resample(X_train, Y_train)\n",
    "    dtc_cv.fit(X_train, Y_train)\n",
    "    Y_pred = dtc_cv.predict(X_test)\n",
    "    matrix = np.add(matrix, confusion_matrix(Y_test, Y_pred)) #Build model and evaluate with testing data\n",
    "    tn, fp, fn, tp=confusion_matrix(np.squeeze(Y_test), np.squeeze(Y_pred)).ravel()\n",
    "    auc=roc_auc_score(Y_test, dtc_cv.predict_proba(X_test)[:, 1])\n",
    "    TN+=tn\n",
    "    FP+=fp\n",
    "    FN+=fn\n",
    "    TP+=tp\n",
    "    AUC+=auc\n",
    "acc=(TN+TP)/(TN+TP+FP+FN)  \n",
    "precision=TP/(TP+FP)\n",
    "recall=TP/(TP+FN)\n",
    "f1=2/(1/precision+1/recall)\n",
    "print(\"ACC\",acc,\"Precision\",precision,\"Recall\",recall,\"F1\",f1,\"AUC\",AUC/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "filled-engagement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 0.68 Precision 0.2857142857142857 Recall 0.4 F1 0.3333333333333333 AUC 0.7070531690531692\n"
     ]
    }
   ],
   "source": [
    "seed=666\n",
    "kf = KFold(n_splits=10, shuffle=True,random_state=seed)\n",
    "matrix = np.matrix('0 0; 0 0') #Generating confusion matrix\n",
    "TN=0\n",
    "FP=0\n",
    "FN=0\n",
    "TP=0\n",
    "AUC=0\n",
    "for train_index, test_index in kf.split(X): #Iterating through each fold of CV\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "    X_train, Y_train = SMOTE(k_neighbors=20,sampling_strategy=0.9).fit_resample(X_train, Y_train)\n",
    "    dtc_cv = GradientBoostingClassifier(n_estimators=500, max_depth=2, max_features='sqrt',learning_rate=0.001)\n",
    "    #ros = RandomOverSampler(random_state=0,sampling_strategy=1.5)\n",
    "   # X_train, Y_train = SMOTE(k_neighbors=20).fit_resample(X_train, Y_train)\n",
    "    #X_train, Y_train = ros.fit_resample(X_train, Y_train)\n",
    "    dtc_cv.fit(X_train, Y_train)\n",
    "    Y_pred = dtc_cv.predict(X_test)\n",
    "    matrix = np.add(matrix, confusion_matrix(Y_test, Y_pred)) #Build model and evaluate with testing data\n",
    "    tn, fp, fn, tp=confusion_matrix(np.squeeze(Y_test), np.squeeze(Y_pred)).ravel()\n",
    "    auc=roc_auc_score(Y_test, dtc_cv.predict_proba(X_test)[:, 1])\n",
    "    TN+=tn\n",
    "    FP+=fp\n",
    "    FN+=fn\n",
    "    TP+=tp\n",
    "    AUC+=auc\n",
    "acc=(TN+TP)/(TN+TP+FP+FN)  \n",
    "precision=TP/(TP+FP)\n",
    "recall=TP/(TP+FN)\n",
    "f1=2/(1/precision+1/recall)\n",
    "print(\"ACC\",acc,\"Precision\",precision,\"Recall\",recall,\"F1\",f1,\"AUC\",AUC/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "revolutionary-advertiser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 0.68 Precision 0.30434782608695654 Recall 0.4666666666666667 F1 0.3684210526315789 AUC 0.7480538350538352\n"
     ]
    }
   ],
   "source": [
    "seed=666\n",
    "kf = KFold(n_splits=10, shuffle=True,random_state=seed)\n",
    "matrix = np.matrix('0 0; 0 0') #Generating confusion matrix\n",
    "TN=0\n",
    "FP=0\n",
    "FN=0\n",
    "TP=0\n",
    "AUC=0\n",
    "for train_index, test_index in kf.split(X): #Iterating through each fold of CV\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "    X_train, Y_train = SMOTE(k_neighbors=20,sampling_strategy=0.8).fit_resample(X_train, Y_train)\n",
    "    dtc_cv = RandomForestClassifier(n_estimators=500, max_depth=2,max_features='sqrt',random_state=0)\n",
    "    #ros = RandomOverSampler(random_state=0,sampling_strategy=1.5)\n",
    "   # X_train, Y_train = SMOTE(k_neighbors=20).fit_resample(X_train, Y_train)\n",
    "    #X_train, Y_train = ros.fit_resample(X_train, Y_train)\n",
    "    dtc_cv.fit(X_train, Y_train)\n",
    "    Y_pred = dtc_cv.predict(X_test)\n",
    "    matrix = np.add(matrix, confusion_matrix(Y_test, Y_pred)) #Build model and evaluate with testing data\n",
    "    tn, fp, fn, tp=confusion_matrix(np.squeeze(Y_test), np.squeeze(Y_pred)).ravel()\n",
    "    auc=roc_auc_score(Y_test, dtc_cv.predict_proba(X_test)[:, 1])\n",
    "    TN+=tn\n",
    "    FP+=fp\n",
    "    FN+=fn\n",
    "    TP+=tp\n",
    "    AUC+=auc\n",
    "acc=(TN+TP)/(TN+TP+FP+FN)  \n",
    "precision=TP/(TP+FP)\n",
    "recall=TP/(TP+FN)\n",
    "f1=2/(1/precision+1/recall)\n",
    "print(\"ACC\",acc,\"Precision\",precision,\"Recall\",recall,\"F1\",f1,\"AUC\",AUC/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "verbal-reason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC 0.68 Precision 0.30434782608695654 Recall 0.4666666666666667 F1 0.3684210526315789 AUC 0.7377295482295483\n"
     ]
    }
   ],
   "source": [
    "seed=666\n",
    "kf = KFold(n_splits=10, shuffle=True,random_state=seed)\n",
    "matrix = np.matrix('0 0; 0 0') #Generating confusion matrix\n",
    "TN=0\n",
    "FP=0\n",
    "FN=0\n",
    "TP=0\n",
    "AUC=0\n",
    "for train_index, test_index in kf.split(X): #Iterating through each fold of CV\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "    X_train, Y_train = SMOTE(k_neighbors=10,sampling_strategy=0.9).fit_resample(X_train, Y_train)\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=5,random_state=0)\n",
    "    dtc_cv = AdaBoostClassifier(base_estimator,learning_rate=0.0001,n_estimators=500,random_state=0)\n",
    "    #ros = RandomOverSampler(random_state=0,sampling_strategy=1.5)\n",
    "   # X_train, Y_train = SMOTE(k_neighbors=20).fit_resample(X_train, Y_train)\n",
    "    #X_train, Y_train = ros.fit_resample(X_train, Y_train)\n",
    "    dtc_cv.fit(X_train, Y_train)\n",
    "    Y_pred = dtc_cv.predict(X_test)\n",
    "    matrix = np.add(matrix, confusion_matrix(Y_test, Y_pred)) #Build model and evaluate with testing data\n",
    "    tn, fp, fn, tp=confusion_matrix(np.squeeze(Y_test), np.squeeze(Y_pred)).ravel()\n",
    "    auc=roc_auc_score(Y_test, dtc_cv.predict_proba(X_test)[:, 1])\n",
    "    TN+=tn\n",
    "    FP+=fp\n",
    "    FN+=fn\n",
    "    TP+=tp\n",
    "    AUC+=auc\n",
    "acc=(TN+TP)/(TN+TP+FP+FN)  \n",
    "precision=TP/(TP+FP)\n",
    "recall=TP/(TP+FN)\n",
    "f1=2/(1/precision+1/recall)\n",
    "print(\"ACC\",acc,\"Precision\",precision,\"Recall\",recall,\"F1\",f1,\"AUC\",AUC/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "frank-ensemble",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py36/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:33:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py36/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:33:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py36/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:33:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py36/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:33:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py36/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:33:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py36/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:33:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py36/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:33:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py36/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:33:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py36/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:33:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/py36/lib/python3.6/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:33:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ACC 0.7133333333333334 Precision 0.35555555555555557 Recall 0.5333333333333333 F1 0.4266666666666667 AUC 0.7447064047064048\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "seed=666\n",
    "kf = KFold(n_splits=10, shuffle=True,random_state=seed)\n",
    "matrix = np.matrix('0 0; 0 0') #Generating confusion matrix\n",
    "TN=0\n",
    "FP=0\n",
    "FN=0\n",
    "TP=0\n",
    "AUC=0\n",
    "for train_index, test_index in kf.split(X): #Iterating through each fold of CV\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "    X_train, Y_train = SMOTE(k_neighbors=20,sampling_strategy=0.9).fit_resample(X_train, Y_train)\n",
    "    #base_estimator=DecisionTreeClassifier(max_depth=5,random_state=0)\n",
    "    dtc_cv = xgb.XGBClassifier(max_depth=3, n_estimators=600, learning_rate=0.01 ,min_child_weight=6,subsample=0.737,reg_alpha=1e-2)\n",
    "    #ros = RandomOverSampler(random_state=0,sampling_strategy=1.5)\n",
    "   # X_train, Y_train = SMOTE(k_neighbors=20).fit_resample(X_train, Y_train)\n",
    "    #X_train, Y_train = ros.fit_resample(X_train, Y_train)\n",
    "    dtc_cv.fit(X_train, Y_train)\n",
    "    Y_pred = dtc_cv.predict(X_test)\n",
    "    matrix = np.add(matrix, confusion_matrix(Y_test, Y_pred)) #Build model and evaluate with testing data\n",
    "    tn, fp, fn, tp=confusion_matrix(np.squeeze(Y_test), np.squeeze(Y_pred)).ravel()\n",
    "    auc=roc_auc_score(Y_test, dtc_cv.predict_proba(X_test)[:, 1])\n",
    "    TN+=tn\n",
    "    FP+=fp\n",
    "    FN+=fn\n",
    "    TP+=tp\n",
    "    AUC+=auc\n",
    "acc=(TN+TP)/(TN+TP+FP+FN)  \n",
    "precision=TP/(TP+FP)\n",
    "recall=TP/(TP+FN)\n",
    "f1=2/(1/precision+1/recall)\n",
    "print(\"ACC\",acc,\"Precision\",precision,\"Recall\",recall,\"F1\",f1,\"AUC\",AUC/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "numerous-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1=2/(1/precision+1/0.56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "surrounded-stomach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4349514563106796"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-latino",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
